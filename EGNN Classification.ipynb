{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c2f63b-359a-4c4f-8f5f-c15589f23c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular EDA (exploratory data analysis) and plotting libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import rdkit\n",
    "from rdkit import RDLogger\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import rdmolops\n",
    "from rdkit.Chem import Descriptors, AllChem, rdMolDescriptors, rdCoordGen\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "IPythonConsole.ipython_useSVG=True\n",
    "%matplotlib inline \n",
    "\n",
    "# ML models\n",
    "import torch\n",
    "from torch.nn import Linear, Dropout\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, global_max_pool, global_mean_pool, radius_graph\n",
    "from torch_geometric.nn import GINConv, GATConv, GraphConv\n",
    "from torch_geometric.nn import GlobalAttention\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.utils import from_smiles\n",
    "import torch.nn.functional as F\n",
    "from e3nn.o3 import Irreps\n",
    "from e3nn.nn import FullyConnectedNet\n",
    "from e3nn.o3 import Irreps\n",
    "from e3nn.nn.models.v2106.gate_points_networks import SimpleNetwork, NetworkForAGraphWithAttributes\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38050cc-6416-4db0-afc8-3dae6c62097a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('BBBP.csv')\n",
    "df = df.sample(n=2000, random_state=42).reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ade69c0-e404-4112-a3ec-03ab6dd65e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>name</th>\n",
       "      <th>p_np</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1812</td>\n",
       "      <td>doliracetam</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=CC=CC2=C1C(C(N2CC(N)=O)=O)C3=CC=CC=C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696</td>\n",
       "      <td>methamphetamine</td>\n",
       "      <td>1</td>\n",
       "      <td>CN[C@@H](C)Cc1ccccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>908</td>\n",
       "      <td>quinacillin</td>\n",
       "      <td>0</td>\n",
       "      <td>CC1(C)S[C@@H]2[C@H](NC(=O)c3nc4ccccc4nc3C(O)=O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>546</td>\n",
       "      <td>GR94839_L</td>\n",
       "      <td>0</td>\n",
       "      <td>c1(CC(N2[C@H](CN(CC2)C(=O)C)C[N@]2CC[C@H](O)C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1851</td>\n",
       "      <td>fluradoline</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=C(F)C=CC3=C1C=C(SCCNC)C2=CC=CC=C2O3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1532</td>\n",
       "      <td>rivastigmine</td>\n",
       "      <td>1</td>\n",
       "      <td>[C@H](C1=CC(=CC=C1)OC(N(CC)C)=O)(N(C)C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>833</td>\n",
       "      <td>fenbenicillin</td>\n",
       "      <td>0</td>\n",
       "      <td>CC1(C)S[C@@H]2[C@H](NC(=O)C(Oc3ccccc3)c4ccccc4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1271</td>\n",
       "      <td>formocortal</td>\n",
       "      <td>1</td>\n",
       "      <td>[C@]12(OC(O[C@@H]1CC3C2(CC(O)[C@@]4(F)C3CC(=C5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1594</td>\n",
       "      <td>tepirindole</td>\n",
       "      <td>1</td>\n",
       "      <td>C3=C(C1=CCN(CCC)CC1)C2=CC(=CC=C2[NH]3)Cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1903</td>\n",
       "      <td>metaxalone</td>\n",
       "      <td>1</td>\n",
       "      <td>C1=C(C=C(C=C1OCC2CNC(O2)=O)C)C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num             name  p_np  \\\n",
       "0     1812      doliracetam     1   \n",
       "1      696  methamphetamine     1   \n",
       "2      908      quinacillin     0   \n",
       "3      546        GR94839_L     0   \n",
       "4     1851      fluradoline     1   \n",
       "...    ...              ...   ...   \n",
       "1995  1532     rivastigmine     1   \n",
       "1996   833    fenbenicillin     0   \n",
       "1997  1271      formocortal     1   \n",
       "1998  1594      tepirindole     1   \n",
       "1999  1903       metaxalone     1   \n",
       "\n",
       "                                                 smiles  \n",
       "0              C1=CC=CC2=C1C(C(N2CC(N)=O)=O)C3=CC=CC=C3  \n",
       "1                                  CN[C@@H](C)Cc1ccccc1  \n",
       "2     CC1(C)S[C@@H]2[C@H](NC(=O)c3nc4ccccc4nc3C(O)=O...  \n",
       "3     c1(CC(N2[C@H](CN(CC2)C(=O)C)C[N@]2CC[C@H](O)C2...  \n",
       "4                C1=C(F)C=CC3=C1C=C(SCCNC)C2=CC=CC=C2O3  \n",
       "...                                                 ...  \n",
       "1995           [C@H](C1=CC(=CC=C1)OC(N(CC)C)=O)(N(C)C)C  \n",
       "1996  CC1(C)S[C@@H]2[C@H](NC(=O)C(Oc3ccccc3)c4ccccc4...  \n",
       "1997  [C@]12(OC(O[C@@H]1CC3C2(CC(O)[C@@]4(F)C3CC(=C5...  \n",
       "1998           C3=C(C1=CCN(CCC)CC1)C2=CC(=CC=C2[NH]3)Cl  \n",
       "1999                     C1=C(C=C(C=C1OCC2CNC(O2)=O)C)C  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b5a469-8e79-4666-9425-d9600babd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_e3nn_graph(smiles, target):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    # Add hydrogens (important for 3D geometry)\n",
    "    mol = Chem.AddHs(mol)\n",
    "\n",
    "    # Generate 3D conformer with ETKDG\n",
    "    if AllChem.EmbedMolecule(mol, AllChem.ETKDG()) != 0:\n",
    "        return None\n",
    "\n",
    "    # UFF optimization\n",
    "    try:\n",
    "        AllChem.UFFOptimizeMolecule(mol)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        conf = mol.GetConformer()\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Atom features and positions\n",
    "    pos = []\n",
    "    node_input = []\n",
    "    node_attr = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        p = conf.GetAtomPosition(atom.GetIdx())\n",
    "        pos.append([p.x, p.y, p.z])\n",
    "\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetTotalNumHs(),\n",
    "            atom.GetFormalCharge(),\n",
    "            int(atom.GetHybridization()),\n",
    "            int(atom.GetIsAromatic()),\n",
    "            atom.GetMass(),\n",
    "            int(atom.GetChiralTag()),\n",
    "            atom.GetImplicitValence()\n",
    "        ]\n",
    "        node_input.append(features)\n",
    "        node_attr.append([1.0])  # Placeholder scalar attr\n",
    "\n",
    "\n",
    "    # Bond features and edge index\n",
    "    edges = []\n",
    "    edge_attr = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edges.extend([[i, j], [j, i]])\n",
    "\n",
    "        bond_feats = [\n",
    "            int(bond.GetBondTypeAsDouble()),  # bond type as float\n",
    "            int(bond.IsInRing()),             # in-ring flag\n",
    "            int(bond.GetIsConjugated())       # conjugation\n",
    "        ]\n",
    "        edge_attr.extend([bond_feats, bond_feats])\n",
    "\n",
    "    try:\n",
    "        data = Data(\n",
    "            pos=torch.tensor(pos, dtype=torch.float),\n",
    "            edge_index=torch.tensor(edges, dtype=torch.long).t().contiguous(),\n",
    "            node_input=torch.tensor(node_input, dtype=torch.float),\n",
    "            node_attr=torch.tensor(node_attr, dtype=torch.float),\n",
    "            edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
    "            y=torch.tensor([target], dtype=torch.float),\n",
    "            smiles=smiles  # optional: keep for eval\n",
    "        )\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe02412-ada5-4437-9f17-3f7f4b553738",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:53:43] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[16:53:56] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "[16:54:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[16:55:03] UFFTYPER: Unrecognized atom type: Ca+2 (0)\n",
      "[16:55:03] UFFTYPER: Unrecognized atom type: Ca+2 (0)\n",
      "[16:55:11] UFFTYPER: Unrecognized charge state for atom: 16\n",
      "[16:55:11] UFFTYPER: Unrecognized charge state for atom: 16\n",
      "[16:55:38] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[16:55:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[16:56:13] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[16:56:15] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[16:56:18] Explicit valence for atom # 12 N, 4, is greater than permitted\n",
      "[16:56:22] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[16:56:22] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[16:56:29] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "RDLogger.DisableLog('rdApp.warning')\n",
    "\n",
    "# Create all graphs with clear argument names\n",
    "graph_list = [\n",
    "    smiles_to_e3nn_graph(\n",
    "        smiles=s,\n",
    "        target=t)\n",
    "    \n",
    "    for s, t in zip(df['smiles'], df['p_np'])\n",
    "]\n",
    "\n",
    "# Filter out failed conformer generations\n",
    "graph_list = [g for g in graph_list if g is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326406d0-18ca-414b-aac3-6d51ddd1473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ratio for splitting the dataset (80% for training, 20% for validation)\n",
    "train_ratio = 0.80\n",
    "\n",
    "# Calculate the total number of samples in the dataset\n",
    "dataset_size = len(graph_list)\n",
    "\n",
    "# Calculate the number of samples for the training and validation sets\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "random_seed = 66\n",
    "generator = torch.Generator().manual_seed(random_seed)\n",
    "\n",
    "# Split the dataset into training and validation subsets\n",
    "train_dataset, val_dataset = random_split(graph_list, [train_size, val_size], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08c952c4-1685-4059-9af3-f163955f803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for the train and val sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d01327-6d7e-49cf-9d7a-fdf80d158aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Equivariant Graph Neural Network Classifier using e3nn and MLP head.\n",
    "    Designed for binary classification with BCEWithLogitsLoss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 radius=3.0,\n",
    "                 num_neighbors=12,\n",
    "                 num_nodes=30,\n",
    "                 mul=50,\n",
    "                 layers=3,\n",
    "                 lmax=2,\n",
    "                 pool_nodes=False,\n",
    "                 hidden_dim1=64,\n",
    "                 hidden_dim2=32,\n",
    "                 dropout=0.7):\n",
    "        \"\"\"\n",
    "        Initialize the E3NNGraphClassifier.\n",
    "\n",
    "        Parameters:\n",
    "            radius (float): Max graph radius for neighbor search.\n",
    "            num_neighbors (int): Max number of neighbors per node.\n",
    "            num_nodes (int): Max number of nodes per graph.\n",
    "            mul (int): Multiplicity for equivariant layers.\n",
    "            layers (int): Number of equivariant layers.\n",
    "            lmax (int): Maximum angular momentum.\n",
    "            pool_nodes (bool): Whether to apply node pooling in equivariant network.\n",
    "            hidden_dim1 (int): First hidden layer dimension in MLP head.\n",
    "            hidden_dim2 (int): Second hidden layer dimension in MLP head.\n",
    "            dropout (float): Dropout probability for MLP head.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define irreducible representations (irreps)\n",
    "        self.irreps_node_input = Irreps(\"9x0e\")      # 9 scalar features per node\n",
    "        self.irreps_node_attr  = Irreps(\"0e\")        # Dummy node attribute (scalar)\n",
    "        self.irreps_edge_attr  = Irreps(\"3x0e\")      # Optional edge attributes (3 scalars)\n",
    "        self.irreps_node_output = Irreps(\"1x0e\")     # Scalar output from equivariant network\n",
    "\n",
    "        # Equivariant GNN Backbone\n",
    "        self.network = NetworkForAGraphWithAttributes(\n",
    "            irreps_node_input=self.irreps_node_input,\n",
    "            irreps_node_attr=self.irreps_node_attr,\n",
    "            irreps_edge_attr=self.irreps_edge_attr,\n",
    "            irreps_node_output=self.irreps_node_output,\n",
    "            max_radius=radius,\n",
    "            num_neighbors=num_neighbors,\n",
    "            num_nodes=num_nodes,\n",
    "            mul=mul,\n",
    "            layers=layers,\n",
    "            lmax=lmax,\n",
    "            pool_nodes=pool_nodes\n",
    "        )\n",
    "\n",
    "        # MLP Head for graph-level classification\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.irreps_node_output.dim * 2, hidden_dim1),  # Combine max & mean pooling\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim2, 1)  # Single output logit for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        \"\"\"\n",
    "        Forward pass of the classifier.\n",
    "\n",
    "        Parameters:\n",
    "            data (torch_geometric.data.Batch): Batch of graph data.\n",
    "\n",
    "        Returns:\n",
    "            logits (torch.Tensor): Raw logits for each graph in the batch.\n",
    "        \"\"\"\n",
    "        # Pass node features through equivariant graph network\n",
    "        node_out = self.network(data)\n",
    "\n",
    "        # Global pooling: concatenate max and mean pooled features across nodes\n",
    "        pooled = torch.cat([\n",
    "            global_max_pool(node_out, data.batch),\n",
    "            global_mean_pool(node_out, data.batch)\n",
    "        ], dim=1)\n",
    "\n",
    "        # Pass pooled features through MLP head to obtain logits\n",
    "        logits = self.mlp(pooled).squeeze(-1)\n",
    "\n",
    "        return logits  # Raw logits (BCEWithLogitsLoss expects logits, not probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3f1aa2e-1ddc-49e2-a710-d6706321afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, else fallback to CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the EGNN Graph Classifier with custom hyperparameters\n",
    "model = EGNN(\n",
    "    radius=3.0,           # Max radius for neighbor search\n",
    "    num_neighbors=16,     # Max neighbors per node\n",
    "    num_nodes=30,         # Max nodes per graph\n",
    "    mul=50,              # Layer multiplicity in equivariant network\n",
    "    layers=3,             # Number of equivariant layers\n",
    "    lmax=2,               # Max angular momentum\n",
    "    hidden_dim1=64,      # First hidden layer size (MLP)\n",
    "    hidden_dim2=32,       # Second hidden layer size (MLP)\n",
    "    dropout=0.7           # Dropout rate in MLP\n",
    ").to(device)\n",
    "\n",
    "# Optimizer: Adam for parameter updates\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "# Learning rate scheduler: halve LR every 10 epochs\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "# Binary classification loss using raw logits\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1824362b-1458-464c-b9c2-b044ffb2e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = total_samples = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(batch)\n",
    "        labels = batch.y.view(-1).float()  # Ensure float type for BCE loss\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * batch.num_graphs\n",
    "        total_samples += batch.num_graphs\n",
    "\n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def val(loader):\n",
    "    model.eval()\n",
    "    total_loss = total_samples = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        labels = batch.y.view(-1).float()\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += float(loss) * batch.num_graphs\n",
    "        total_samples += batch.num_graphs\n",
    "\n",
    "    return total_loss / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c68a033-bc6a-4c33-9980-d02371b0bb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25 | Train Loss: 0.5918, Validation Loss: 0.5922\n",
      "Epoch: 2/25 | Train Loss: 0.5818, Validation Loss: 0.5604\n",
      "Epoch: 3/25 | Train Loss: 0.5569, Validation Loss: 0.5578\n",
      "Epoch: 4/25 | Train Loss: 0.5786, Validation Loss: 0.5498\n",
      "Epoch: 5/25 | Train Loss: 0.5730, Validation Loss: 0.5493\n",
      "Epoch: 6/25 | Train Loss: 0.5713, Validation Loss: 0.5476\n",
      "Epoch: 7/25 | Train Loss: 0.5496, Validation Loss: 0.5430\n",
      "Epoch: 8/25 | Train Loss: 0.5392, Validation Loss: 0.5137\n",
      "Epoch: 9/25 | Train Loss: 0.5320, Validation Loss: 0.4804\n",
      "Epoch: 10/25 | Train Loss: 0.5244, Validation Loss: 0.4883\n",
      "Epoch: 11/25 | Train Loss: 0.5017, Validation Loss: 0.4670\n",
      "Epoch: 12/25 | Train Loss: 0.4960, Validation Loss: 0.4802\n",
      "Epoch: 13/25 | Train Loss: 0.5119, Validation Loss: 0.4829\n",
      "Epoch: 14/25 | Train Loss: 0.4777, Validation Loss: 0.4678\n",
      "Epoch: 15/25 | Train Loss: 0.4883, Validation Loss: 0.4675\n",
      "Epoch: 16/25 | Train Loss: 0.4801, Validation Loss: 0.5171\n",
      "Epoch: 17/25 | Train Loss: 0.4648, Validation Loss: 0.4450\n",
      "Epoch: 18/25 | Train Loss: 0.4587, Validation Loss: 0.4456\n",
      "Epoch: 19/25 | Train Loss: 0.4493, Validation Loss: 0.4240\n",
      "Epoch: 20/25 | Train Loss: 0.4357, Validation Loss: 0.4205\n",
      "Epoch: 21/25 | Train Loss: 0.4230, Validation Loss: 0.3942\n",
      "Epoch: 22/25 | Train Loss: 0.3982, Validation Loss: 0.3941\n",
      "Epoch: 23/25 | Train Loss: 0.4057, Validation Loss: 0.3888\n",
      "Epoch: 24/25 | Train Loss: 0.4121, Validation Loss: 0.3972\n",
      "Epoch: 25/25 | Train Loss: 0.3952, Validation Loss: 0.3908\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "\n",
    "# Initialize lists to store training and val scores (RMSE values)\n",
    "score_train = []\n",
    "score_val = []\n",
    "\n",
    "# Set the number of epochs for training\n",
    "epochs = 25\n",
    "\n",
    "# Loop over each epoch for training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train the model and get the training RMSE\n",
    "    train_rmse = train(train_loader)\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validate the model and get the val RMSE\n",
    "    val_rmse = val(val_loader)\n",
    "\n",
    "    # Append the training RMSE and val RMSE to their respective lists\n",
    "    score_train.append(train_rmse)\n",
    "    score_val.append(val_rmse)\n",
    "\n",
    "    # Print the progress of the training process (epoch number, train loss, val loss)\n",
    "    print(f'Epoch: {epoch+1}/{epochs} | Train Loss: {train_rmse:.4f}, '\n",
    "          f'Validation Loss: {val_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f559109b-dbd0-44e7-902c-cda76426cb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(loader):\n",
    "    model.eval()\n",
    "    preds, trues, smi = [], [], []\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        logits = model(batch)\n",
    "        probs = torch.sigmoid(logits)   # Convert logits to probabilities\n",
    "        preds.append(probs.cpu())\n",
    "        trues.append(batch.y.view(-1).cpu())\n",
    "        smi.extend(batch.smiles)\n",
    "\n",
    "    preds = torch.cat(preds).numpy()\n",
    "    trues = torch.cat(trues).numpy()\n",
    "\n",
    "    df_result = pd.DataFrame({\n",
    "        'smiles': smi,\n",
    "        'actual': trues,\n",
    "        'probability': preds,\n",
    "        'pred': (preds >= 0.5).astype(int)\n",
    "    })\n",
    "\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8894b66e-ec61-40ca-8e38-ba3e57ffc543",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_res = eval_model(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e37559a-9a13-4e07-b032-98736c0d5c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary(y_true, y_prob):\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"Accuracy : {acc:.4f}\")\n",
    "    print(f\"ROC-AUC  : {auc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"roc_auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"f1_score\": round(f1, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cb229e6-fa9b-4e79-aadc-c4b7cbc2d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8186\n",
      "ROC-AUC  : 0.6463\n",
      "Precision: 0.8149\n",
      "Recall   : 0.9833\n",
      "F1-score : 0.8912\n"
     ]
    }
   ],
   "source": [
    "evaluate_binary(val_res['actual'], val_res['pred']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2e360-792c-42fd-89b8-703a17e7692c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
